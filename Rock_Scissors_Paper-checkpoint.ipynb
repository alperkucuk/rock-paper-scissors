{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m CATEGORIES \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(DIRECTORY)\n\u001b[0;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame( columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGaussian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSobel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m \u001b[43mwarnings\u001b[49m\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import warnings\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy import ndimage as nd\n",
    "from skimage.filters import sobel\n",
    "\n",
    "# Data directory and data category \n",
    "DIRECTORY = r\"C:\\Users\\lenovo\\Desktop\\Rock-Paper-Scissors\\train\"\n",
    "CATEGORIES = os.listdir(DIRECTORY)\n",
    "df = pd.DataFrame( columns = ['Entropy', 'Gaussian', 'Sobel'])\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data = []\n",
    "labels = []\n",
    "features = []\n",
    "# get all the data and labels in given directory\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    filelist = os.listdir(path)\n",
    "    for fichier in filelist[:]: # filelist[:] makes a copy of filelist.\n",
    "        if not(fichier.endswith(\".png\")):\n",
    "            filelist.remove(fichier)\n",
    "    \n",
    "    for img in filelist:\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path)\n",
    "        \n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        \n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img2 = img.reshape(-1)\n",
    "\n",
    "\n",
    "        entropy_img = entropy(img, disk(1))\n",
    "\n",
    "        entropy1 = entropy_img.reshape(-1).mean()\n",
    "        features.append(entropy1) \n",
    "\n",
    "        \n",
    "\n",
    "       \n",
    "\n",
    "        gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "\n",
    "        gaussian_img1 = gaussian_img.reshape(-1).mean()\n",
    "        features.append(gaussian_img1) \n",
    "\n",
    "        sobel_img = sobel(img)\n",
    "\n",
    "        sobel1 = sobel_img.reshape(-1).mean()\n",
    "        features.append(sobel1) \n",
    "        \n",
    "        \n",
    "        df.loc[len(df.index)] = features\n",
    "        \n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        labels.append(category)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('entropy', entropy_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('gaussian', gaussian_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('sobel', sobel_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "\n",
    "# check the data count and balance  \n",
    "counter=collections.Counter(labels)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import l1_min_c\n",
    "\n",
    "ks = [3,5,7,10]\n",
    "\n",
    "for k in ks:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores = cross_val_score(\n",
    "    knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    \n",
    "    print('KNN K={} ile Train Başarısı {}'.format(k,scores.mean()*100))\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "    knn, X_test, y_test, cv=10, scoring='accuracy')\n",
    "    \n",
    "    print('KNN K={} ile Test Başarısı {}'.format(k,scores.mean()*100))\n",
    "    \n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    clf = SVC(kernel=kernel)\n",
    "    scores = cross_val_score(\n",
    "        clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    print('SVM Kernel={} ile train Başarısı {}'.format(kernel,scores.mean()*100))\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        clf, X_test, y_test, cv=10, scoring='accuracy')    \n",
    "    \n",
    "    print('SVM Kernel={} ile test Başarısı {}'.format(kernel,scores.mean()*100))\n",
    "\n",
    "    \n",
    "# Applying Decision Tree\n",
    "clf = DecisionTreeClassifier( criterion='entropy',random_state=0,max_depth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "scores_train = cross_val_score(\n",
    "    clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "\n",
    "scores_test = cross_val_score(\n",
    "    clf, X_test, y_test, cv=10, scoring='accuracy')\n",
    "\n",
    "print('Decision Train Tree Başarısı = {}'.format((scores_train.mean()*100)))\n",
    "print('Decision Test Tree Başarısı = {}'.format((scores_test.mean()*100)))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "scores_train = cross_val_score(\n",
    "    knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "\n",
    "scores_test = cross_val_score(\n",
    "    knn, X_test, y_test, cv=10, scoring='accuracy')\n",
    "\n",
    "print('KNN Train Başarısı = {}'.format((scores_train.mean()*100)))\n",
    "print('KNN Test Başarısı = {}'.format((scores_test.mean()*100)))\n",
    "\n",
    "\n",
    "cs = l1_min_c(X, y, loss=\"log\") * np.logspace(0, 7, 16)\n",
    "\n",
    "reg = LogisticRegression(\n",
    "    penalty=\"l1\",\n",
    "    solver=\"liblinear\",\n",
    "    tol=1e-6,\n",
    "    max_iter=int(1e6),\n",
    "    warm_start=True,\n",
    "    intercept_scaling=10000.0,\n",
    ")\n",
    "\n",
    "coefs_ = []\n",
    "for c in cs:\n",
    "    reg.set_params(C=c)\n",
    "    reg.fit(X, y)\n",
    "    coefs_.append(reg.coef_.ravel().copy())\n",
    "\n",
    "coefs_ = np.array(coefs_)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "scores_train = cross_val_score(\n",
    "    reg, X_train, y_train, cv=10, scoring='accuracy')\n",
    "scores_test = cross_val_score(\n",
    "    reg, X_test, y_test, cv=10, scoring='accuracy')\n",
    "\n",
    "print('Logistic Regression = {}'.format((scores_train.mean()*100)))\n",
    "print('logistic Regression = {}'.format((scores_test.mean()*100)))\n",
    "\n",
    "plt.plot(np.log10(cs), coefs_, marker=\"o\")\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.xlabel(\"log(C)\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.title(\"Logistic Regression Path\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = ['Rock', 'Scissors', 'Paper']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        knn,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy import ndimage as nd\n",
    "from skimage.filters import sobel\n",
    "\n",
    "# Data directory and data category \n",
    "DIRECTORY = r\"C:\\Users\\lenovo\\Desktop\\Rock-Paper-Scissors\\pred\"\n",
    "CATEGORIES = os.listdir(DIRECTORY)\n",
    "df = pd.DataFrame( columns = ['Entropy', 'Gaussian', 'Sobel'])\n",
    "\n",
    "data = []\n",
    "features = []\n",
    "# get all the data and labels in given directory\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    filelist = os.listdir(path)\n",
    "    for fichier in filelist[:]: # filelist[:] makes a copy of filelist.\n",
    "        if not(fichier.endswith(\".png\")):\n",
    "            filelist.remove(fichier)\n",
    "    \n",
    "    for img in filelist:\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path)\n",
    "        \n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        \n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img2 = img.reshape(-1)\n",
    "\n",
    "\n",
    "        entropy_img = entropy(img, disk(1))\n",
    "\n",
    "        entropy1 = entropy_img.reshape(-1).mean()\n",
    "        features.append(entropy1) \n",
    "\n",
    "        \n",
    "\n",
    "       \n",
    "\n",
    "        gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "\n",
    "        gaussian_img1 = gaussian_img.reshape(-1).mean()\n",
    "        features.append(gaussian_img1) \n",
    "\n",
    "        sobel_img = sobel(img)\n",
    "\n",
    "        sobel1 = sobel_img.reshape(-1).mean()\n",
    "        features.append(sobel1) \n",
    "        \n",
    "        \n",
    "        df.loc[len(df.index)] = features\n",
    "        \n",
    "        \n",
    "        features = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
